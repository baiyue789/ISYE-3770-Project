{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean CSV code like a basic clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "file_path = 'dbird_data_Georgia_Tech_final(1).csv' \n",
    "dfoG = pd.read_csv(file_path)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = dfoG[dfoG.duplicated()]\n",
    "print(f\"Number of duplicate rows: {len(duplicate_rows)}\")\n",
    "\n",
    "# Drop the columns 'notes' and 'image'\n",
    "dfoG = dfoG.drop(columns=['notes', 'image', 'created_at_utc','updated_at_utc', 'location_accuracy_meters', 'mobile_device_gps_source'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'observed_at_utc' column to datetime\n",
    "dfoG['observed_at_utc'] = pd.to_datetime(dfoG['observed_at_utc'], format='mixed', errors='coerce')\n",
    "\n",
    "# Format the datetime to only include the date (YYYY-MM-DD)\n",
    "dfoG['observed_at_utc'] = dfoG['observed_at_utc'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame back to a CSV if needed\n",
    "dfoG.to_csv('updated_dbird.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the new cleaned CSV data to calculate everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'updated_dbird.csv'\n",
    "df = pd.read_csv('updated_dbird.csv')\n",
    "\n",
    "# Define latitude and longitude bounds\n",
    "top_latitude = 33.77592\n",
    "bottom_latitude = 33.77495\n",
    "left_longitude = -84.40163\n",
    "right_longitude = -84.40106\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'observed_at_utc' column to datetime\n",
    "df['observed_at_utc'] = pd.to_datetime(df['observed_at_utc'], format='mixed', errors='coerce')\n",
    "\n",
    "# Format the datetime to only include the date (YYYY-MM-DD)\n",
    "df['observed_at_utc'] = df['observed_at_utc'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows within the latitude and longitude range\n",
    "df_2024_within_bounds = df[\n",
    "    (df['latitude'] <= top_latitude) &\n",
    "    (df['latitude'] >= bottom_latitude) &\n",
    "    (df['longitude'] >= left_longitude) &\n",
    "    (df['longitude'] <= right_longitude)\n",
    "]\n",
    "# Rows in 2024 but outside bounds\n",
    "df_2024_outside_bounds = df.drop(df_2024_within_bounds.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df_2024_within_bounds.to_csv('dbird_2024_within_bounds.csv', index=False)\n",
    "df_2024_outside_bounds.to_csv('dbird_2024_outside_bounds.csv', index=False)\n",
    "\n",
    "print(\"Files saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df_2024_outside_bounds.to_csv('dbird_2024_outside_bounds.csv', index=False)\n",
    "\n",
    "print(\"Files saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcualting the Mean and std of dbird_2024_outside_bounds (df1) (data for Q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data saved from this run is in the yearly_data where it's split off by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Saved data for 2017-2024.\n",
      "outside bounds data\n",
      "\n",
      "Number of files processed: 8\n",
      "\n",
      "Mean size of datasets: 61.25\n",
      "Mean excluding outliers 60.875\n",
      "\n",
      "Standard deviation of dataset sizes: 78.75413821326651\n",
      "Standard Deviation excluding outliers: 68.62154666478064\n",
      "\n",
      "inside bounds data\n",
      "\n",
      "bird data within bounds mean: 11\n",
      "bird data within bounds Standard deviation: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# File path to the input dataset\n",
    "file_path = \"dbird_2024_outside_bounds.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df1 = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the 'observed_at_utc' column is in datetime format\n",
    "df1['observed_at_utc'] = pd.to_datetime(df1['observed_at_utc'], errors='coerce')\n",
    "\n",
    "# Extract the year from the 'observed_at_utc' column\n",
    "df1['year'] = df1['observed_at_utc'].dt.year\n",
    "\n",
    "# Folder to save the yearly CSV files\n",
    "output_folder = \"yearly_data\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Split the data into yearly CSV files (2017-2024)\n",
    "for year in range(2017, 2025):\n",
    "    year_df = df1[df1['year'] == year]  # Filter for the current year\n",
    "    output_file = os.path.join(output_folder, f'dbird_data_{year}.csv')  # Create file path in the folder\n",
    "    year_df.to_csv(output_file, index=False)  # Save to a CSV file\n",
    "print(\"Success: Saved data for 2017-2024.\")\n",
    "\n",
    "# Initialize a list to store the sizes of each year's dataset\n",
    "sizes = []\n",
    "\n",
    "# Calculate the size (number of rows) for each CSV file\n",
    "for year in range(2017, 2025):\n",
    "    filepath = os.path.join(output_folder, f'dbird_data_{year}.csv')  # Update path to include folder\n",
    "    try:\n",
    "        tmeancalc = pd.read_csv(filepath)\n",
    "        sizes.append(len(tmeancalc))  # Add the number of rows to the sizes list\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filepath} not found. Skipping...\")\n",
    "\n",
    "# Calculate the mean of the sizes\n",
    "mean_size = sum(sizes) / len(sizes) \n",
    "mean_exsize = sum(sizes[4:]) / len(sizes)\n",
    "\n",
    "# Calculate the standard deviation of the sizes\n",
    "std_deviation = pd.Series(sizes).std()\n",
    "# Calculate the standard deviation for the list excluding the first 4 elements, if applicable\n",
    "if len(sizes) > 4:\n",
    "    outliers_ex = pd.Series(sizes[4:]).std()\n",
    "else:\n",
    "    outliers_ex = 0\n",
    "\n",
    "# Output the results\n",
    "print(\"outside bounds data\\n\")\n",
    "print(f\"Number of files processed: {len(sizes)}\")\n",
    "print(\"\")\n",
    "print(f\"Mean size of datasets: {mean_size}\")\n",
    "print(f\"Mean excluding outliers {mean_exsize}\")\n",
    "print(\"\")\n",
    "print(f\"Standard deviation of dataset sizes: {std_deviation}\")\n",
    "print(f\"Standard Deviation excluding outliers: {outliers_ex}\")\n",
    "print(\"\")\n",
    "print(\"inside bounds data\\n\")\n",
    "print(f\"bird data within bounds mean: {len(pd.read_csv('dbird_2024_within_bounds.csv'))}\")\n",
    "print(\"bird data within bounds Standard deviation: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Saved data for 2017-2024 by month.\n"
     ]
    }
   ],
   "source": [
    "# Split the data into monthly CSV files\n",
    "output_folder = \"Monthly_yearly_data\"\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for year in range(2017, 2025):\n",
    "    for month in range(1, 13):\n",
    "        # Filter for the current year and month\n",
    "        month_df = df1[(df1['year'] == year) & (df1['observed_at_utc'].dt.month == month)]\n",
    "        \n",
    "        # Skip if there's no data for the current month\n",
    "        if month_df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Create the file path\n",
    "        output_file = os.path.join(output_folder, f'dbird_data_{year}_{month:02d}.csv')\n",
    "        \n",
    "        # Save to a CSV file\n",
    "        month_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Success: Saved data for 2017-2024 by month.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "within bounds\n",
      "\n",
      "Mean size of datasets (monthly): 11.951219512195122\n",
      "Standard deviation of dataset sizes (monthly): 16.502956128391354\n",
      "Monthly statistics saved to 'monthly_statistics.csv'.\n",
      "Summary statistics saved to 'summary_statistics.txt'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "print(\"within bounds\")\n",
    "print(\"\")\n",
    "# Folder containing the monthly data\n",
    "input_folder = \"Monthly_yearly_data\"\n",
    "\n",
    "# Initialize a dictionary to store the sizes for each month\n",
    "monthly_sizes = {}\n",
    "\n",
    "# Loop through the monthly files and collect sizes\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".csv\") and \"_\" in file_name:  # Ensure it's a monthly file\n",
    "        parts = file_name.split('_')\n",
    "        \n",
    "        # Check if the file name has at least four parts\n",
    "        if len(parts) < 4:\n",
    "            print(f\"Skipping file with unexpected format: {file_name}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Extract year and month from the file name\n",
    "            year = parts[2]\n",
    "            month = parts[3].split('.')[0]\n",
    "            \n",
    "            # Load the CSV file\n",
    "            file_path = os.path.join(input_folder, file_name)\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Add the size to the dictionary\n",
    "            key = f\"{year}-{int(month):02d}\"  # Format as \"YYYY-MM\"\n",
    "            monthly_sizes[key] = len(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "# Convert the sizes to a DataFrame for easier calculations\n",
    "sizes_df = pd.DataFrame(list(monthly_sizes.items()), columns=[\"Month\", \"Size\"])\n",
    "sizes_df['Month'] = pd.to_datetime(sizes_df['Month'], format='%Y-%m')\n",
    "\n",
    "# Sort by Month for clarity\n",
    "sizes_df = sizes_df.sort_values(by=\"Month\")\n",
    "\n",
    "# Calculate statistics\n",
    "mean_size = sizes_df['Size'].mean()\n",
    "std_deviation = sizes_df['Size'].std()\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean size of datasets (monthly): {mean_size}\")\n",
    "print(f\"Standard deviation of dataset sizes (monthly): {std_deviation}\")\n",
    "\n",
    "# Save the statistics and monthly data to a CSV file\n",
    "sizes_df.to_csv(\"monthly_statistics.csv\", index=False)\n",
    "print(\"Monthly statistics saved to 'monthly_statistics.csv'.\")\n",
    "\n",
    "# Save calculated stats to a separate file\n",
    "with open(\"summary_statistics.txt\", \"w\") as summary_file:\n",
    "    summary_file.write(f\"Mean size of datasets (monthly): {mean_size:.2f}\\n\")\n",
    "    summary_file.write(f\"Standard deviation of dataset sizes (monthly): {std_deviation:.2f}\\n\")\n",
    "print(\"Summary statistics saved to 'summary_statistics.txt'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outside bounds\n",
      "\n",
      "Mean count of observations per month: 1.8333333333333333\n",
      "Standard deviation of observations per month: 1.1690451944500122\n",
      "\n",
      "Monthly counts:\n",
      "  year_month  count\n",
      "0    2022-10      2\n",
      "1    2023-01      1\n",
      "2    2023-04      2\n",
      "3    2023-08      1\n",
      "4    2024-02      4\n",
      "5    2024-09      1\n"
     ]
    }
   ],
   "source": [
    "print(\"outside bounds\")\n",
    "print(\"\")\n",
    "# Load the data into a DataFrame\n",
    "df = pd.read_csv(\"dbird_2024_within_bounds.csv\")\n",
    "\n",
    "# Convert the 'observed_at_utc' column to datetime\n",
    "df['observed_at_utc'] = pd.to_datetime(df['observed_at_utc'])\n",
    "\n",
    "# Extract the year and month\n",
    "df['year_month'] = df['observed_at_utc'].dt.to_period('M')\n",
    "\n",
    "# Group by month and count the number of records\n",
    "monthly_counts = df.groupby('year_month').size().reset_index(name='count')\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_count = monthly_counts['count'].mean()\n",
    "std_dev_count = monthly_counts['count'].std()\n",
    "\n",
    "# Print results\n",
    "print(\"Mean count of observations per month:\", mean_count)\n",
    "print(\"Standard deviation of observations per month:\", std_dev_count)\n",
    "\n",
    "# Display the monthly counts\n",
    "print(\"\\nMonthly counts:\")\n",
    "print(monthly_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the bird Species (df2) (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_name\n",
      "Ovenbird                   44\n",
      "Tennessee Warbler          28\n",
      "Gray Catbird               22\n",
      "American Robin             21\n",
      "Swainson's Thrush          19\n",
      "                           ..\n",
      "White-breasted Nuthatch     1\n",
      "Dark-eyed Junco             1\n",
      "Carolina Chickadee          1\n",
      "Red-shouldered Hawk         1\n",
      "Hooded Warbler              1\n",
      "Name: count, Length: 70, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"updated_dbird.csv\"\n",
    "\n",
    "df2 = pd.read_csv(file_path)\n",
    "\n",
    "cleaned_df = df2[(df2[\"common_name\"]!='unknown' )]\n",
    "\n",
    "bird_counts = cleaned_df['common_name'].value_counts()\n",
    "\n",
    "print(bird_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate by Year which half has more collisions (data for Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Folder to save the yearly CSV files\n",
    "output_folder = \"yearly_data\"\n",
    "Half1_folder = \"yearly_data_spring\"\n",
    "Half2_folder = \"yearly_data_Fall\"\n",
    "\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(Half1_folder, exist_ok=True)\n",
    "os.makedirs(Half2_folder, exist_ok=True)\n",
    "\n",
    "for year in range(2017, 2025):\n",
    "    filepath = os.path.join(output_folder, f'dbird_data_{year}.csv')  # Path to the yearly file\n",
    "    \n",
    "    try:\n",
    "        # Read the file\n",
    "        current_file = pd.read_csv(filepath)\n",
    "\n",
    "        # Ensure the observed_at_utc is in datetime format\n",
    "        current_file['observed_at_utc'] = pd.to_datetime(current_file['observed_at_utc'])\n",
    "\n",
    "        # Filter for months 1-6 (Spring)\n",
    "        first_half = current_file[current_file['observed_at_utc'].dt.month.isin(range(1, 7))]\n",
    "        spring_output_file = os.path.join(Half1_folder, f'dbird_data_{year}_spring.csv')\n",
    "        first_half.to_csv(spring_output_file, index=False)  # Save spring data to CSV\n",
    "\n",
    "        # Filter for months 7-12 (Fall)\n",
    "        second_half = current_file[current_file['observed_at_utc'].dt.month.isin(range(7, 13))]\n",
    "        fall_output_file = os.path.join(Half2_folder, f'dbird_data_{year}_fall.csv')\n",
    "        second_half.to_csv(fall_output_file, index=False)  # Save fall data to CSV\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found at {filepath}. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing year {year}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spring (Months 1-6):\n",
      "Sizes: [0, 0, 0, 0, 1, 41, 52, 39]\n",
      "Mean: 16.625\n",
      "Mean cleaned: 16.625\n",
      "Median: 0.5\n",
      "Standard Deviation: 22.977862016670368\n",
      "Standard Deviation: 22.246722605064026 (cleaned)\n",
      "\n",
      "Fall (Months 7-12):\n",
      "Sizes: [3, 0, 0, 0, 22, 139, 99, 94]\n",
      "Mean: 44.625\n",
      "Mean cleaned: 44.25\n",
      "Median: 12.5\n",
      "Standard Deviation: 56.7197055704629\n",
      "Standard Deviation: 48.692915295759406 (cleaned)\n"
     ]
    }
   ],
   "source": [
    "# Folders to save the yearly CSV files\n",
    "output_folder = \"yearly_data\"\n",
    "Half1_folder = \"yearly_data_spring\"\n",
    "Half2_folder = \"yearly_data_fall\"\n",
    "\n",
    "# Initialize lists to store the sizes of each half's datasets\n",
    "spring_sizes = []\n",
    "fall_sizes = []\n",
    "\n",
    "# Process each year's data\n",
    "for year in range(2017, 2025):\n",
    "    filepath = os.path.join(output_folder, f'dbird_data_{year}.csv')  # Path to the yearly file\n",
    "    \n",
    "    try:\n",
    "        # Read the file\n",
    "        current_file = pd.read_csv(filepath)\n",
    "\n",
    "        # Ensure the observed_at_utc is in datetime format\n",
    "        current_file['observed_at_utc'] = pd.to_datetime(current_file['observed_at_utc'])\n",
    "\n",
    "        # Filter for months 1-6 (Spring)\n",
    "        spring_data = current_file[current_file['observed_at_utc'].dt.month.isin(range(1, 7))]\n",
    "        spring_sizes.append(len(spring_data))  # Store size of the spring dataset\n",
    "\n",
    "        # Filter for months 7-12 (Fall)\n",
    "        fall_data = current_file[current_file['observed_at_utc'].dt.month.isin(range(7, 13))]\n",
    "        fall_sizes.append(len(fall_data))  # Store size of the fall dataset\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found at {filepath}. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing year {year}: {e}\")\n",
    "\n",
    "# Calculate statistics for Spring (Months 1-6)\n",
    "spring_mean = sum(spring_sizes) / len(spring_sizes) \n",
    "spring_median = pd.Series(spring_sizes).median() \n",
    "\n",
    "# Calculate statistics for Fall (Months 7-12)\n",
    "fall_mean = sum(fall_sizes) / len(fall_sizes) \n",
    "fall_median = pd.Series(fall_sizes).median() \n",
    "\n",
    "if len(sizes) > 4:\n",
    "    Spring_outliers_ex = pd.Series(spring_sizes[4:]).std()\n",
    "else:\n",
    "    Spring_outliers_ex = 0\n",
    "    \n",
    "if len(sizes) > 4:\n",
    "    Fall_outliers_ex = pd.Series(fall_sizes[4:]).std()\n",
    "else:\n",
    "    Fall_outliers_ex = 0\n",
    "\n",
    "\n",
    "SPmean_exsize = sum(spring_sizes[4:]) / len(spring_sizes)\n",
    "FALLmean_exsize = sum(fall_sizes[4:]) / len(fall_sizes)\n",
    "# Output results\n",
    "print(\"Spring (Months 1-6):\")\n",
    "print(f\"Sizes: {spring_sizes}\")\n",
    "print(f\"Mean: {spring_mean}\")\n",
    "print(f\"Mean cleaned: {SPmean_exsize}\")\n",
    "print(f\"Median: {spring_median}\")\n",
    "print(f\"Standard Deviation: {pd.Series(spring_sizes).std()}\")\n",
    "print(f\"Standard Deviation: {Spring_outliers_ex} (cleaned)\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Fall (Months 7-12):\")\n",
    "print(f\"Sizes: {fall_sizes}\")\n",
    "print(f\"Mean: {fall_mean}\")\n",
    "print(f\"Mean cleaned: {FALLmean_exsize}\")\n",
    "print(f\"Median: {fall_median}\")\n",
    "print(f\"Standard Deviation: {pd.Series(fall_sizes).std()}\")\n",
    "print(f\"Standard Deviation: {Fall_outliers_ex} (cleaned)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fro Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spring (Months Feb-Jun):\n",
      "Sizes: [0, 0, 0, 0, 1, 39, 49, 37]\n",
      "Mean: 15.75\n",
      "Mean cleaned: 15.75\n",
      "Median: 0.5\n",
      "Standard Deviation: 20.33316256758894\n",
      "Standard Deviation (cleaned): 20.33316256758894\n",
      "\n",
      "Fall (Months Aug-Nov):\n",
      "Sizes: [3, 0, 0, 0, 18, 132, 93, 92]\n",
      "Mean: 42.25\n",
      "Mean cleaned: 42.25\n",
      "Median: 10.5\n",
      "Standard Deviation: 50.73152373031979\n",
      "Standard Deviation (cleaned): 50.73152373031979\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Folder to save the yearly CSV files\n",
    "output_folder = \"yearly_data\"\n",
    "Half1_folder = \"yearly_data_spring\"\n",
    "Half2_folder = \"yearly_data_fall\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(Half1_folder, exist_ok=True)\n",
    "os.makedirs(Half2_folder, exist_ok=True)\n",
    "\n",
    "# Initialize lists to store sizes for spring and fall datasets\n",
    "spring_sizes = []\n",
    "fall_sizes = []\n",
    "\n",
    "for year in range(2017, 2025):\n",
    "    filepath = os.path.join(output_folder, f'dbird_data_{year}.csv')  # Path to the yearly file\n",
    "    \n",
    "    try:\n",
    "        # Read the file\n",
    "        current_file = pd.read_csv(filepath)\n",
    "\n",
    "        # Ensure the observed_at_utc is in datetime format\n",
    "        current_file['observed_at_utc'] = pd.to_datetime(current_file['observed_at_utc'])\n",
    "\n",
    "        # Filter for months 2-6 (Spring)\n",
    "        first_half = current_file[current_file['observed_at_utc'].dt.month.isin(range(2, 7))]\n",
    "        spring_output_file = os.path.join(Half1_folder, f'dbird_data_{year}_spring.csv')\n",
    "        first_half.to_csv(spring_output_file, index=False)  # Save spring data to CSV\n",
    "        spring_sizes.append(len(first_half))  # Store the size of the spring data\n",
    "\n",
    "        # Filter for months 8-11 (Fall)\n",
    "        second_half = current_file[current_file['observed_at_utc'].dt.month.isin(range(8, 12))]\n",
    "        fall_output_file = os.path.join(Half2_folder, f'dbird_data_{year}_fall.csv')\n",
    "        second_half.to_csv(fall_output_file, index=False)  # Save fall data to CSV\n",
    "        fall_sizes.append(len(second_half))  # Store the size of the fall data\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found at {filepath}. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing year {year}: {e}\")\n",
    "\n",
    "# Spring statistics\n",
    "spring_mean = np.mean(spring_sizes)\n",
    "spring_median = np.median(spring_sizes)\n",
    "spring_std = np.std(spring_sizes)\n",
    "\n",
    "# Clean spring data (removing outliers)\n",
    "spring_cleaned = [size for size in spring_sizes if abs(size - spring_mean) <= 2 * spring_std]\n",
    "SPmean_exsize = np.mean(spring_cleaned)\n",
    "Spring_outliers_ex = np.std(spring_cleaned)\n",
    "\n",
    "# Fall statistics\n",
    "fall_mean = np.mean(fall_sizes)\n",
    "fall_median = np.median(fall_sizes)\n",
    "fall_std = np.std(fall_sizes)\n",
    "\n",
    "# Clean fall data (removing outliers)\n",
    "fall_cleaned = [size for size in fall_sizes if abs(size - fall_mean) <= 2 * fall_std]\n",
    "FALLmean_exsize = np.mean(fall_cleaned)\n",
    "Fall_outliers_ex = np.std(fall_cleaned)\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Spring (Months Feb-Jun):\")\n",
    "print(f\"Sizes: {spring_sizes}\")\n",
    "print(f\"Mean: {spring_mean}\")\n",
    "print(f\"Mean cleaned: {SPmean_exsize}\")\n",
    "print(f\"Median: {spring_median}\")\n",
    "print(f\"Standard Deviation: {spring_std}\")\n",
    "print(f\"Standard Deviation (cleaned): {Spring_outliers_ex}\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Fall (Months Aug-Nov):\")\n",
    "print(f\"Sizes: {fall_sizes}\")\n",
    "print(f\"Mean: {fall_mean}\")\n",
    "print(f\"Mean cleaned: {FALLmean_exsize}\")\n",
    "print(f\"Median: {fall_median}\")\n",
    "print(f\"Standard Deviation: {fall_std}\")\n",
    "print(f\"Standard Deviation (cleaned): {Fall_outliers_ex}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
