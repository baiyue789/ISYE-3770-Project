{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean CSV code like a basic clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "file_path = 'dbird_data_Georgia_Tech_final(1).csv' \n",
    "dfoG = pd.read_csv(file_path)\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = dfoG[dfoG.duplicated()]\n",
    "print(f\"Number of duplicate rows: {len(duplicate_rows)}\")\n",
    "\n",
    "# Drop the columns 'notes' and 'image'\n",
    "dfoG = dfoG.drop(columns=['notes', 'image', 'created_at_utc','updated_at_utc', 'location_accuracy_meters', 'mobile_device_gps_source'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'observed_at_utc' column to datetime\n",
    "dfoG['observed_at_utc'] = pd.to_datetime(dfoG['observed_at_utc'], format='mixed', errors='coerce')\n",
    "\n",
    "# Format the datetime to only include the date (YYYY-MM-DD)\n",
    "dfoG['observed_at_utc'] = dfoG['observed_at_utc'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated DataFrame back to a CSV if needed\n",
    "dfoG.to_csv('updated_dbird.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the new cleaned CSV data to calculate everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'updated_dbird.csv'\n",
    "df = pd.read_csv('updated_dbird.csv')\n",
    "\n",
    "# Define latitude and longitude bounds\n",
    "top_latitude = 33.77592\n",
    "bottom_latitude = 33.77495\n",
    "left_longitude = -84.40163\n",
    "right_longitude = -84.40106\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'observed_at_utc' column to datetime\n",
    "df['observed_at_utc'] = pd.to_datetime(df['observed_at_utc'], format='mixed', errors='coerce')\n",
    "\n",
    "# Format the datetime to only include the date (YYYY-MM-DD)\n",
    "df['observed_at_utc'] = df['observed_at_utc'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows within the latitude and longitude range\n",
    "df_2024_within_bounds = df[\n",
    "    (df['latitude'] <= top_latitude) &\n",
    "    (df['latitude'] >= bottom_latitude) &\n",
    "    (df['longitude'] >= left_longitude) &\n",
    "    (df['longitude'] <= right_longitude)\n",
    "]\n",
    "# Rows in 2024 but outside bounds\n",
    "df_2024_outside_bounds = df.drop(df_2024_within_bounds.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df_2024_within_bounds.to_csv('dbird_2024_within_bounds.csv', index=False)\n",
    "df_2024_outside_bounds.to_csv('dbird_2024_outside_bounds.csv', index=False)\n",
    "\n",
    "print(\"Files saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully!\n"
     ]
    }
   ],
   "source": [
    "df_2024_outside_bounds.to_csv('dbird_2024_outside_bounds.csv', index=False)\n",
    "\n",
    "print(\"Files saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcualting the Mean and std of dbird_2024_outside_bounds (df1) (data for Q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data saved from this run is in the yearly_data where it's split off by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Saved data for 2017-2024.\n",
      "Number of files processed: 8\n",
      "\n",
      "Mean size of datasets: 61.25\n",
      "Mean excluding outliers 60.875\n",
      "\n",
      "Standard deviation of dataset sizes: 78.75413821326651\n",
      "Standard Deviation excluding outliers: 68.62154666478064\n",
      "\n",
      "bird data within bounds mean: 11\n",
      "bird data within bounds Standard deviation: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# File path to the input dataset\n",
    "file_path = \"dbird_2024_outside_bounds.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df1 = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure the 'observed_at_utc' column is in datetime format\n",
    "df1['observed_at_utc'] = pd.to_datetime(df1['observed_at_utc'], errors='coerce')\n",
    "\n",
    "# Extract the year from the 'observed_at_utc' column\n",
    "df1['year'] = df1['observed_at_utc'].dt.year\n",
    "\n",
    "# Folder to save the yearly CSV files\n",
    "output_folder = \"yearly_data\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Split the data into yearly CSV files (2017-2024)\n",
    "for year in range(2017, 2025):\n",
    "    year_df = df1[df1['year'] == year]  # Filter for the current year\n",
    "    output_file = os.path.join(output_folder, f'dbird_data_{year}.csv')  # Create file path in the folder\n",
    "    year_df.to_csv(output_file, index=False)  # Save to a CSV file\n",
    "print(\"Success: Saved data for 2017-2024.\")\n",
    "\n",
    "# Initialize a list to store the sizes of each year's dataset\n",
    "sizes = []\n",
    "\n",
    "# Calculate the size (number of rows) for each CSV file\n",
    "for year in range(2017, 2025):\n",
    "    filepath = os.path.join(output_folder, f'dbird_data_{year}.csv')  # Update path to include folder\n",
    "    try:\n",
    "        tmeancalc = pd.read_csv(filepath)\n",
    "        sizes.append(len(tmeancalc))  # Add the number of rows to the sizes list\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {filepath} not found. Skipping...\")\n",
    "\n",
    "# Calculate the mean of the sizes\n",
    "mean_size = sum(sizes) / len(sizes) \n",
    "mean_exsize = sum(sizes[4:]) / len(sizes)\n",
    "\n",
    "# Calculate the standard deviation of the sizes\n",
    "std_deviation = pd.Series(sizes).std()\n",
    "# Calculate the standard deviation for the list excluding the first 4 elements, if applicable\n",
    "if len(sizes) > 4:\n",
    "    outliers_ex = pd.Series(sizes[4:]).std()\n",
    "else:\n",
    "    outliers_ex = 0\n",
    "\n",
    "# Output the results\n",
    "print(f\"Number of files processed: {len(sizes)}\")\n",
    "print(\"\")\n",
    "print(f\"Mean size of datasets: {mean_size}\")\n",
    "print(f\"Mean excluding outliers {mean_exsize}\")\n",
    "print(\"\")\n",
    "print(f\"Standard deviation of dataset sizes: {std_deviation}\")\n",
    "print(f\"Standard Deviation excluding outliers: {outliers_ex}\")\n",
    "print(\"\")\n",
    "print(f\"bird data within bounds mean: {len(pd.read_csv('dbird_2024_within_bounds.csv'))}\")\n",
    "print(\"bird data within bounds Standard deviation: 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the bird Species (df2) (Extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common_name\n",
      "Ovenbird                   44\n",
      "Tennessee Warbler          28\n",
      "Gray Catbird               22\n",
      "American Robin             21\n",
      "Swainson's Thrush          19\n",
      "                           ..\n",
      "White-breasted Nuthatch     1\n",
      "Dark-eyed Junco             1\n",
      "Carolina Chickadee          1\n",
      "Red-shouldered Hawk         1\n",
      "Hooded Warbler              1\n",
      "Name: count, Length: 70, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"updated_dbird.csv\"\n",
    "\n",
    "df2 = pd.read_csv(file_path)\n",
    "\n",
    "cleaned_df = df2[(df2[\"common_name\"]!='unknown' )]\n",
    "\n",
    "bird_counts = cleaned_df['common_name'].value_counts()\n",
    "\n",
    "print(bird_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate by Year which half has more collisions (data for Q3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "# Folder to save the yearly CSV files\n",
    "output_folder = \"yearly_data\"\n",
    "Half1_folder = \"yearly_data_spring\"\n",
    "Half2_folder = \"yearly_data_Fall\"\n",
    "\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(Half1_folder, exist_ok=True)\n",
    "os.makedirs(Half2_folder, exist_ok=True)\n",
    "\n",
    "for year in range(2017, 2025):\n",
    "    filepath = os.path.join(output_folder, f'dbird_data_{year}.csv')  # Path to the yearly file\n",
    "    \n",
    "    try:\n",
    "        # Read the file\n",
    "        current_file = pd.read_csv(filepath)\n",
    "\n",
    "        # Ensure the observed_at_utc is in datetime format\n",
    "        current_file['observed_at_utc'] = pd.to_datetime(current_file['observed_at_utc'])\n",
    "\n",
    "        # Filter for months 1-6 (Spring)\n",
    "        first_half = current_file[current_file['observed_at_utc'].dt.month.isin(range(1, 7))]\n",
    "        spring_output_file = os.path.join(Half1_folder, f'dbird_data_{year}_spring.csv')\n",
    "        first_half.to_csv(spring_output_file, index=False)  # Save spring data to CSV\n",
    "\n",
    "        # Filter for months 7-12 (Fall)\n",
    "        second_half = current_file[current_file['observed_at_utc'].dt.month.isin(range(7, 13))]\n",
    "        fall_output_file = os.path.join(Half2_folder, f'dbird_data_{year}_fall.csv')\n",
    "        second_half.to_csv(fall_output_file, index=False)  # Save fall data to CSV\n",
    "\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found at {filepath}. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing year {year}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spring (Months 1-6):\n",
      "Sizes: [0, 0, 0, 0, 1, 41, 52, 39]\n",
      "Mean: 16.625\n",
      "Mean cleaned: 16.625\n",
      "Median: 0.5\n",
      "Standard Deviation: 22.977862016670368\n",
      "Standard Deviation: 22.246722605064026 (cleaned)\n",
      "\n",
      "Fall (Months 7-12):\n",
      "Sizes: [3, 0, 0, 0, 22, 139, 99, 94]\n",
      "Mean: 44.625\n",
      "Mean cleaned: 44.25\n",
      "Median: 12.5\n",
      "Standard Deviation: 56.7197055704629\n",
      "Standard Deviation: 48.692915295759406 (cleaned)\n"
     ]
    }
   ],
   "source": [
    "# Folders to save the yearly CSV files\n",
    "output_folder = \"yearly_data\"\n",
    "Half1_folder = \"yearly_data_spring\"\n",
    "Half2_folder = \"yearly_data_fall\"\n",
    "\n",
    "# Initialize lists to store the sizes of each half's datasets\n",
    "spring_sizes = []\n",
    "fall_sizes = []\n",
    "\n",
    "# Process each year's data\n",
    "for year in range(2017, 2025):\n",
    "    filepath = os.path.join(output_folder, f'dbird_data_{year}.csv')  # Path to the yearly file\n",
    "    \n",
    "    try:\n",
    "        # Read the file\n",
    "        current_file = pd.read_csv(filepath)\n",
    "\n",
    "        # Ensure the observed_at_utc is in datetime format\n",
    "        current_file['observed_at_utc'] = pd.to_datetime(current_file['observed_at_utc'])\n",
    "\n",
    "        # Filter for months 1-6 (Spring)\n",
    "        spring_data = current_file[current_file['observed_at_utc'].dt.month.isin(range(1, 7))]\n",
    "        spring_sizes.append(len(spring_data))  # Store size of the spring dataset\n",
    "\n",
    "        # Filter for months 7-12 (Fall)\n",
    "        fall_data = current_file[current_file['observed_at_utc'].dt.month.isin(range(7, 13))]\n",
    "        fall_sizes.append(len(fall_data))  # Store size of the fall dataset\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File for year {year} not found at {filepath}. Skipping...\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing year {year}: {e}\")\n",
    "\n",
    "# Calculate statistics for Spring (Months 1-6)\n",
    "spring_mean = sum(spring_sizes) / len(spring_sizes) \n",
    "spring_median = pd.Series(spring_sizes).median() \n",
    "\n",
    "# Calculate statistics for Fall (Months 7-12)\n",
    "fall_mean = sum(fall_sizes) / len(fall_sizes) \n",
    "fall_median = pd.Series(fall_sizes).median() \n",
    "\n",
    "if len(sizes) > 4:\n",
    "    Spring_outliers_ex = pd.Series(spring_sizes[4:]).std()\n",
    "else:\n",
    "    Spring_outliers_ex = 0\n",
    "    \n",
    "if len(sizes) > 4:\n",
    "    Fall_outliers_ex = pd.Series(fall_sizes[4:]).std()\n",
    "else:\n",
    "    Fall_outliers_ex = 0\n",
    "\n",
    "\n",
    "SPmean_exsize = sum(spring_sizes[4:]) / len(spring_sizes)\n",
    "FALLmean_exsize = sum(fall_sizes[4:]) / len(fall_sizes)\n",
    "# Output results\n",
    "print(\"Spring (Months 1-6):\")\n",
    "print(f\"Sizes: {spring_sizes}\")\n",
    "print(f\"Mean: {spring_mean}\")\n",
    "print(f\"Mean cleaned: {SPmean_exsize}\")\n",
    "print(f\"Median: {spring_median}\")\n",
    "print(f\"Standard Deviation: {pd.Series(spring_sizes).std()}\")\n",
    "print(f\"Standard Deviation: {Spring_outliers_ex} (cleaned)\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"Fall (Months 7-12):\")\n",
    "print(f\"Sizes: {fall_sizes}\")\n",
    "print(f\"Mean: {fall_mean}\")\n",
    "print(f\"Mean cleaned: {FALLmean_exsize}\")\n",
    "print(f\"Median: {fall_median}\")\n",
    "print(f\"Standard Deviation: {pd.Series(fall_sizes).std()}\")\n",
    "print(f\"Standard Deviation: {Fall_outliers_ex} (cleaned)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fro Q4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
